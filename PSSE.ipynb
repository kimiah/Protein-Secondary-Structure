{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Protein Secondary Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: substrings of length 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sub_str_len = 7\n",
    "max_len = 15\n",
    "def preprocess():\n",
    "    data = pd.DataFrame(columns=['substr', 'Structure'])\n",
    "    files = glob('../DSSP/*.dssp')\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f, delimiter=' ')\n",
    "        structure = df['Structure']\n",
    "        amino_acid = df['AA']\n",
    "        idx = []  # list of indices\n",
    "        cumsum = [0]\n",
    "        for i in range(1, len(df)):\n",
    "            cumsum.append(cumsum[i - 1] + 1 if structure[i] == structure[i - 1] else 0)\n",
    "\n",
    "        for i in range(len(df) - sub_str_len):\n",
    "            if cumsum[i + sub_str_len - 1] == sub_str_len - 1 and \\\n",
    "                    (i + sub_str_len == len(cumsum) or cumsum[i + sub_str_len] == 0):\n",
    "                idx.append(i)\n",
    "                data = data.append({'substr': ' '.join(amino_acid[i: i + sub_str_len]),\n",
    "                                    'Structure': structure[i]}, ignore_index=True)\n",
    "    #     print(\"f: %s\" % f)\n",
    "    #     print(idx)\n",
    "    #  data.to_csv('data.csv')\n",
    "    #  data = pd.read_csv('data.csv')\n",
    "    df = data.substr.str.split(' ', expand=True)\n",
    "    df.columns = ['AA%d' % i for i in range(1, sub_str_len + 1)]\n",
    "    df['label'] = data['Structure']\n",
    "    df = df.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "    df.to_csv('data_final.csv', index=False)\n",
    "\n",
    "# preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Categorical to Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: There was a problem loading OrdinalEncoder in the jupyter notebook so I run this part in python console and saved the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# , OrdinalEncoder\n",
    "\n",
    "def transform(input_file_name='data_final', str_len=sub_str_len):\n",
    "    df = pd.read_csv('data/' + input_file_name + '.csv')\n",
    "    cols = ['AA%d' % i for i in range(1, str_len + 1)]\n",
    "    df_cols = df[cols]\n",
    "    cat_encoder = OneHotEncoder(sparse=False,\n",
    "                                categories=[list(string.ascii_uppercase) for _ in range(str_len)], handle_unknown='ignore')\n",
    "    df_1hots = cat_encoder.fit_transform(df_cols)\n",
    "    mat = df_1hots\n",
    "    df_1hots = (mat.T[~np.all(mat.T == 0, axis=1)]).T\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    labels_encoded = ordinal_encoder.fit_transform(df[['label']])\n",
    "    # data = np.hstack((df_1hots, labels_encoded))\n",
    "    data = np.concatenate((df_1hots, labels_encoded), axis=1)\n",
    "    np.save('data/' + input_file_name + '_transformed.npy', data)\n",
    "    y = data[:, -1]\n",
    "    X = data[:, :-1]\n",
    "    return X, y\n",
    "\n",
    "# X, y = transform()\n",
    "data = np.load('data/data_final_transformed.npy')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "n_classes = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 and 4: Random Forest Classifier and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "depths = [int(x) for x in np.linspace(10, 110, num = 5)]\n",
    "depths.append(None)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 800, num = 3)]\n",
    "\n",
    "# val_acc = np.zeros((len(n_estimators), len(depths)))\n",
    "# for i in range(len(n_estimators)):\n",
    "#     for j in range(len(depths)):\n",
    "#         rfc = RandomForestClassifier(n_estimators = n_estimators[i],\n",
    "#                                      max_depth=depths[j],\n",
    "#                                      criterion = 'entropy', random_state = 42)\n",
    "#         val_acc[i][j] = cross_val_score(rfc, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "rfc = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "\n",
    "def search(depths, n_estimators):\n",
    "    param_grid = {\n",
    "        # \"max_features\": [1, 3, 10],\n",
    "        # \"min_samples_split\": [2, 3, 10],\n",
    "        \"max_depth\": depths,\n",
    "        \"n_estimators\": n_estimators,\n",
    "        # \"bootstrap\": [True, False],\n",
    "        # \"criterion\": [\"gini\", \"entropy\"]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5, return_train_score=True, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search\n",
    "\n",
    "grid_search1 = search(depths, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_search(grid_search):\n",
    "    df_gridsearch = pd.DataFrame(grid_search.cv_results_)\n",
    "    df_gridsearch.head()\n",
    "\n",
    "    max_scores = df_gridsearch.groupby(['param_max_depth', 'param_n_estimators']).max()\n",
    "    max_scores = max_scores.unstack()[['mean_test_score', 'mean_train_score']]\n",
    "    sns.heatmap(max_scores.mean_test_score, annot=True, fmt='.4g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_search(grid_search1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since we are using sklearn \"classifiers\", their score function would be the accurecy not SSE error. Therefore, one-hot encoding is not needed for the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report(clf):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Train Score: \")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(\"Test Score: \")\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"Report: \")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] max_depth=60, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=60, n_estimators=300 ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... max_depth=60, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=60, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=60, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=60, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=60, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=60, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=60, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=60, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=60, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=60, n_estimators=500, total=   7.7s\n",
      "[CV] max_depth=70, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=70, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=70, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=300, total=   4.6s\n",
      "[CV] max_depth=70, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=300, total=   4.5s\n",
      "[CV] max_depth=70, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=300, total=   4.5s\n",
      "[CV] max_depth=70, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=70, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=70, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=70, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=70, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=70, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=80, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=80, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=80, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=80, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=80, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=300, total=   4.5s\n",
      "[CV] max_depth=80, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=80, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=500, total=   8.4s\n",
      "[CV] max_depth=80, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=500, total=   9.0s\n",
      "[CV] max_depth=80, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=500, total=  10.3s\n",
      "[CV] max_depth=80, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=80, n_estimators=500, total=  10.2s\n",
      "[CV] max_depth=90, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=90, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=90, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=90, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=90, n_estimators=300 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=300, total=   4.5s\n",
      "[CV] max_depth=90, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=500, total=  10.5s\n",
      "[CV] max_depth=90, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=500, total=   7.7s\n",
      "[CV] max_depth=90, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=90, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=500, total=   7.9s\n",
      "[CV] max_depth=90, n_estimators=500 ..................................\n",
      "[CV] ................... max_depth=90, n_estimators=500, total=   9.1s\n",
      "[CV] max_depth=100, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=300, total=   6.3s\n",
      "[CV] max_depth=100, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=300, total=   6.8s\n",
      "[CV] max_depth=100, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=300, total=   6.9s\n",
      "[CV] max_depth=100, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=300, total=   7.8s\n",
      "[CV] max_depth=100, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=300, total=   5.9s\n",
      "[CV] max_depth=100, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=500, total=   9.6s\n",
      "[CV] max_depth=100, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=500, total=   9.6s\n",
      "[CV] max_depth=100, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=500, total=  10.6s\n",
      "[CV] max_depth=100, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=500, total=  10.5s\n",
      "[CV] max_depth=100, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=100, n_estimators=500, total=   9.1s\n",
      "[CV] max_depth=110, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=300, total=   5.5s\n",
      "[CV] max_depth=110, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=300, total=   5.4s\n",
      "[CV] max_depth=110, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=300, total=   6.2s\n",
      "[CV] max_depth=110, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=300, total=   5.2s\n",
      "[CV] max_depth=110, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=300, total=   4.7s\n",
      "[CV] max_depth=110, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=500, total=   8.2s\n",
      "[CV] max_depth=110, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=500, total=   7.3s\n",
      "[CV] max_depth=110, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=500, total=   8.2s\n",
      "[CV] max_depth=110, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=110, n_estimators=500, total=  11.1s\n",
      "[CV] max_depth=110, n_estimators=500 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_depth=110, n_estimators=500, total=  10.2s\n",
      "[CV] max_depth=120, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=300, total=   5.7s\n",
      "[CV] max_depth=120, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=300, total=   5.5s\n",
      "[CV] max_depth=120, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=300, total=   6.0s\n",
      "[CV] max_depth=120, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=300, total=   6.6s\n",
      "[CV] max_depth=120, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=300, total=   5.5s\n",
      "[CV] max_depth=120, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=500, total=   9.4s\n",
      "[CV] max_depth=120, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=500, total=   8.8s\n",
      "[CV] max_depth=120, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=120, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=120, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=120, n_estimators=500, total=   7.4s\n",
      "[CV] max_depth=130, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=130, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=130, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=130, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=130, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=130, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=130, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=130, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=130, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=130, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=130, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=140, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=140, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=140, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=140, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=300, total=   4.6s\n",
      "[CV] max_depth=140, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=140, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=140, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=140, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=140, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=500, total=   7.3s\n",
      "[CV] max_depth=140, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=140, n_estimators=500, total=   7.5s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=300, total=   5.1s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=300, total=   6.6s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=150, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=150, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=150, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=500, total=   7.4s\n",
      "[CV] max_depth=150, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=150, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=150, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=150, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=160, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=160, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=160, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=160, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=160, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=300, total=   4.4s\n",
      "[CV] max_depth=160, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=160, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=160, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=160, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=160, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=160, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=170, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=170, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=170, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=170, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=170, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=170, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=170, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=170, n_estimators=500 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. max_depth=170, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=170, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=170, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=170, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=180, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=180, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=180, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=180, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=180, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=180, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=180, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=180, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=180, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=180, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=180, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=190, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=190, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=300, total=   4.3s\n",
      "[CV] max_depth=190, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=190, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=190, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=300, total=   4.2s\n",
      "[CV] max_depth=190, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=190, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=500, total=   7.1s\n",
      "[CV] max_depth=190, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=500, total=   6.9s\n",
      "[CV] max_depth=190, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=500, total=   6.8s\n",
      "[CV] max_depth=190, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=190, n_estimators=500, total=   6.7s\n",
      "[CV] max_depth=200, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=200, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=200, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=200, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=200, n_estimators=300 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=200, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=200, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=200, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=500, total=   7.0s\n",
      "[CV] max_depth=200, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=500, total=   8.2s\n",
      "[CV] max_depth=200, n_estimators=500 .................................\n",
      "[CV] .................. max_depth=200, n_estimators=500, total=   9.4s\n",
      "[CV] max_depth=None, n_estimators=300 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=300, total=   4.6s\n",
      "[CV] max_depth=None, n_estimators=300 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=300, total=   4.7s\n",
      "[CV] max_depth=None, n_estimators=300 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=None, n_estimators=300 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=300, total=   4.5s\n",
      "[CV] max_depth=None, n_estimators=300 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=300, total=   4.1s\n",
      "[CV] max_depth=None, n_estimators=500 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=500, total=   7.2s\n",
      "[CV] max_depth=None, n_estimators=500 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=500, total=   7.3s\n",
      "[CV] max_depth=None, n_estimators=500 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=500, total=   8.2s\n",
      "[CV] max_depth=None, n_estimators=500 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=500, total=   8.0s\n",
      "[CV] max_depth=None, n_estimators=500 ................................\n",
      "[CV] ................. max_depth=None, n_estimators=500, total=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 18.5min finished\n"
     ]
    }
   ],
   "source": [
    "depths = [int(x) for x in np.linspace(60, 200, num = 15)]\n",
    "depths.append(None)\n",
    "n_estimators = [300, 500]\n",
    "\n",
    "grid_search2 = search(depths, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_search(grid_search2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: \n",
      "0.9994532531437944\n",
      "Test Score: \n",
      "0.932536893886156\n",
      "Confusion Matrix: \n",
      "[[875   0   7   0   0   0]\n",
      " [  1  18   2   0   0   0]\n",
      " [ 47   0 386   0   0   0]\n",
      " [  2   0   3   4   0   0]\n",
      " [ 19   0   7   0  18   0]\n",
      " [  4   0   3   0   1  26]]\n",
      "Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.99      0.96       882\n",
      "        1.0       1.00      0.86      0.92        21\n",
      "        2.0       0.95      0.89      0.92       433\n",
      "        3.0       1.00      0.44      0.62         9\n",
      "        4.0       0.95      0.41      0.57        44\n",
      "        5.0       1.00      0.76      0.87        34\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300, max_depth=160, criterion='entropy', random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "report(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 5: MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I tried many other options for hidden layers (varying also the number of hidden layers) and looked at the validation data, but the two layer network below is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation scores: \n",
      "0.9262007028504491\n",
      "0.9246388129636861\n",
      "0.9359625146427177\n",
      "0.9359375\n",
      "0.931640625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(128, ))\n",
    "print(\"Validation scores: \")\n",
    "for train_indices, val_indices in kf.split(X_train):\n",
    "    mlp.fit(X_train[train_indices], y_train[train_indices])\n",
    "    print(mlp.score(X_train[val_indices], y_train[val_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: \n",
      "0.9994532531437944\n",
      "Test Score: \n",
      "0.9297259311314126\n",
      "Confusion Matrix: \n",
      "[[863   0  10   0   7   2]\n",
      " [  0  18   2   0   0   1]\n",
      " [ 35   1 391   0   4   2]\n",
      " [  1   1   2   4   1   0]\n",
      " [ 10   1   4   0  22   7]\n",
      " [  1   1   2   0   5  25]]\n",
      "Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.98      0.96       882\n",
      "        1.0       0.82      0.86      0.84        21\n",
      "        2.0       0.95      0.90      0.93       433\n",
      "        3.0       1.00      0.44      0.62         9\n",
      "        4.0       0.56      0.50      0.53        44\n",
      "        5.0       0.68      0.74      0.70        34\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "report(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['substr', 'Structure'])\n",
    "max_len = 15\n",
    "min_len = 2\n",
    "\n",
    "files = glob('../DSSP/*.dssp')\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, delimiter=' ')\n",
    "    structure = df['Structure']\n",
    "    amino_acid = df['AA']\n",
    "    idx = []  # list of indices\n",
    "    cumsum = [0]\n",
    "    for i in range(1, len(df)):\n",
    "        cumsum.append(cumsum[i - 1] + 1 if structure[i] == structure[i - 1] else 0)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if i == 1 or cumsum[i] == 0:\n",
    "            str_len = cumsum[i - 1] + 1\n",
    "            if min_len <= str_len <= max_len:\n",
    "                idx.append(i - str_len)\n",
    "                data = data.append({\n",
    "                    'substr': (''.join(amino_acid[i - str_len: i]).zfill(max_len)),\n",
    "                    'Structure': structure[i - 1]}, ignore_index=True)\n",
    "    data.to_csv('data/var_raw.csv')\n",
    "\n",
    "df = data.substr.str.split('', expand=True)\n",
    "columns = df.columns.tolist()\n",
    "cols_to_use = columns[1:len(columns) - 1]\n",
    "df = df[cols_to_use]\n",
    "df.columns = ['AA%d' % i for i in range(1, max_len + 1)]\n",
    "df['label'] = data['Structure']\n",
    "df = df.applymap(lambda s:s.upper() if type(s) == str else s)\n",
    "df.to_csv('data/var.csv', index=False)\n",
    "X, y = transform('var', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292670, 365)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data/var_transformed.npy')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "n_classes = len(np.unique(y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [int(x) for x in np.linspace(60, 300, num = 15)]\n",
    "depths.append(None)\n",
    "n_estimators = [200]\n",
    "\n",
    "grid_search = search(depths, n_estimators)\n",
    "\n",
    "# did not have enough time and resouces to run on jupyter again but the optimal hyperparameters are set in final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: \n",
      "0.8267195134451771\n",
      "Test Score: \n",
      "0.7840954518896645\n",
      "Confusion Matrix: \n",
      "[[   8   25    2    0    0   39  107]\n",
      " [   1 7390  124  123    1  318  683]\n",
      " [   0  123 2091   30    0  154  237]\n",
      " [   0  185   41 4786    3   41   66]\n",
      " [   0   26    2    8  215    3    6]\n",
      " [   3  340  301   43    0 2428 2501]\n",
      " [   0  243  381   55    2  804 8580]]\n",
      "Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      0.04      0.08       181\n",
      "        1.0       0.89      0.86      0.87      8640\n",
      "        2.0       0.71      0.79      0.75      2635\n",
      "        3.0       0.95      0.93      0.94      5122\n",
      "        4.0       0.97      0.83      0.89       260\n",
      "        5.0       0.64      0.43      0.52      5616\n",
      "        6.0       0.70      0.85      0.77     10065\n",
      "\n",
      "avg / total       0.78      0.78      0.78     32519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=210, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "report(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88268215\n",
      "Iteration 2, loss = 0.74568435\n",
      "Iteration 3, loss = 0.69764084\n",
      "Iteration 4, loss = 0.66704916\n",
      "Iteration 5, loss = 0.64552313\n",
      "Iteration 6, loss = 0.62856249\n",
      "Iteration 7, loss = 0.61535405\n",
      "Iteration 8, loss = 0.60419833\n",
      "Iteration 9, loss = 0.59470846\n",
      "Iteration 10, loss = 0.58690358\n",
      "Iteration 11, loss = 0.57976353\n",
      "Iteration 12, loss = 0.57328049\n",
      "Iteration 13, loss = 0.56797417\n",
      "Iteration 14, loss = 0.56245913\n",
      "Iteration 15, loss = 0.55801983\n",
      "Iteration 16, loss = 0.55342190\n",
      "Iteration 17, loss = 0.54902503\n",
      "Iteration 18, loss = 0.54537946\n",
      "Iteration 19, loss = 0.54173637\n",
      "Iteration 20, loss = 0.53865343\n",
      "Iteration 21, loss = 0.53520421\n",
      "Iteration 22, loss = 0.53217288\n",
      "Iteration 23, loss = 0.52952283\n",
      "Iteration 24, loss = 0.52717641\n",
      "Iteration 25, loss = 0.52501507\n",
      "Iteration 26, loss = 0.52235755\n",
      "Iteration 27, loss = 0.51980240\n",
      "Iteration 28, loss = 0.51810280\n",
      "Iteration 29, loss = 0.51641224\n",
      "Iteration 30, loss = 0.51412423\n",
      "Iteration 31, loss = 0.51280566\n",
      "Iteration 32, loss = 0.51034763\n",
      "Iteration 33, loss = 0.50853535\n",
      "Iteration 34, loss = 0.50674113\n",
      "Iteration 35, loss = 0.50564602\n",
      "Iteration 36, loss = 0.50319062\n",
      "Iteration 37, loss = 0.50292819\n",
      "Iteration 38, loss = 0.50134961\n",
      "Iteration 39, loss = 0.49969148\n",
      "Iteration 40, loss = 0.49901533\n",
      "Iteration 41, loss = 0.49758097\n",
      "Iteration 42, loss = 0.49623742\n",
      "Iteration 43, loss = 0.49540011\n",
      "Iteration 44, loss = 0.49368800\n",
      "Iteration 45, loss = 0.49311193\n",
      "Iteration 46, loss = 0.49178396\n",
      "Iteration 47, loss = 0.49096592\n",
      "Iteration 48, loss = 0.48940024\n",
      "Iteration 49, loss = 0.48888795\n",
      "Iteration 50, loss = 0.48780748\n",
      "Iteration 51, loss = 0.48725679\n",
      "Iteration 52, loss = 0.48590716\n",
      "Iteration 53, loss = 0.48510687\n",
      "Iteration 54, loss = 0.48485537\n",
      "Iteration 55, loss = 0.48388686\n",
      "Iteration 56, loss = 0.48286413\n",
      "Iteration 57, loss = 0.48217947\n",
      "Iteration 58, loss = 0.48129951\n",
      "Iteration 59, loss = 0.48045209\n",
      "Iteration 60, loss = 0.47979537\n",
      "Iteration 61, loss = 0.47967921\n",
      "Iteration 62, loss = 0.47880481\n",
      "Iteration 63, loss = 0.47845418\n",
      "Iteration 64, loss = 0.47700096\n",
      "Iteration 65, loss = 0.47705189\n",
      "Iteration 66, loss = 0.47604785\n",
      "Iteration 67, loss = 0.47518034\n",
      "Iteration 68, loss = 0.47498485\n",
      "Iteration 69, loss = 0.47421510\n",
      "Iteration 70, loss = 0.47410079\n",
      "Iteration 71, loss = 0.47302033\n",
      "Iteration 72, loss = 0.47306336\n",
      "Iteration 73, loss = 0.47156967\n",
      "Iteration 74, loss = 0.47190818\n",
      "Iteration 75, loss = 0.47151127\n",
      "Iteration 76, loss = 0.47053484\n",
      "Iteration 77, loss = 0.47037591\n",
      "Iteration 78, loss = 0.46997394\n",
      "Iteration 79, loss = 0.46961166\n",
      "Iteration 80, loss = 0.46921479\n",
      "Iteration 81, loss = 0.46848426\n",
      "Iteration 82, loss = 0.46792368\n",
      "Iteration 83, loss = 0.46816730\n",
      "Iteration 84, loss = 0.46761976\n",
      "Iteration 85, loss = 0.46781112\n",
      "Iteration 86, loss = 0.46715568\n",
      "Iteration 87, loss = 0.46678453\n",
      "Iteration 88, loss = 0.46592974\n",
      "Iteration 89, loss = 0.46536387\n",
      "Iteration 90, loss = 0.46493674\n",
      "Iteration 91, loss = 0.46554086\n",
      "Iteration 92, loss = 0.46430127\n",
      "Iteration 93, loss = 0.46401827\n",
      "Iteration 94, loss = 0.46433820\n",
      "Iteration 95, loss = 0.46332978\n",
      "Iteration 96, loss = 0.46310272\n",
      "Iteration 97, loss = 0.46247137\n",
      "Iteration 98, loss = 0.46215994\n",
      "Iteration 99, loss = 0.46236586\n",
      "Iteration 100, loss = 0.46230805\n",
      "Iteration 101, loss = 0.46122196\n",
      "Iteration 102, loss = 0.46102993\n",
      "Iteration 103, loss = 0.46094152\n",
      "Iteration 104, loss = 0.46074125\n",
      "Iteration 105, loss = 0.45986535\n",
      "Iteration 106, loss = 0.46050458\n",
      "Iteration 107, loss = 0.45955072\n",
      "Iteration 108, loss = 0.45960763\n",
      "Iteration 109, loss = 0.45962864\n",
      "Iteration 110, loss = 0.45934395\n",
      "Iteration 111, loss = 0.45888699\n",
      "Iteration 112, loss = 0.45891444\n",
      "Iteration 113, loss = 0.45875116\n",
      "Iteration 114, loss = 0.45804011\n",
      "Iteration 115, loss = 0.45794506\n",
      "Iteration 116, loss = 0.45776039\n",
      "Iteration 117, loss = 0.45701129\n",
      "Iteration 118, loss = 0.45712620\n",
      "Iteration 119, loss = 0.45703348\n",
      "Iteration 120, loss = 0.45675062\n",
      "Iteration 121, loss = 0.45668854\n",
      "Iteration 122, loss = 0.45576779\n",
      "Iteration 123, loss = 0.45568804\n",
      "Iteration 124, loss = 0.45561000\n",
      "Iteration 125, loss = 0.45518750\n",
      "Iteration 126, loss = 0.45559342\n",
      "Iteration 127, loss = 0.45557680\n",
      "Iteration 128, loss = 0.45555611\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Train Score: \n",
      "0.814586394232412\n",
      "Test Score: \n",
      "0.7715796918724438\n",
      "Confusion Matrix: \n",
      "[[   6   23    2    0    0   39  111]\n",
      " [   2 7159  122  169   15  382  791]\n",
      " [   0  116 1964   42    1  210  302]\n",
      " [   0  187   39 4729   16   68   83]\n",
      " [   0   22    5    7  211    7    8]\n",
      " [   1  266  280   62    9 2338 2660]\n",
      " [   2  173  337   62    4  803 8684]]\n",
      "Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.03      0.06       181\n",
      "        1.0       0.90      0.83      0.86      8640\n",
      "        2.0       0.71      0.75      0.73      2635\n",
      "        3.0       0.93      0.92      0.93      5122\n",
      "        4.0       0.82      0.81      0.82       260\n",
      "        5.0       0.61      0.42      0.49      5616\n",
      "        6.0       0.69      0.86      0.76     10065\n",
      "\n",
      "avg / total       0.77      0.77      0.76     32519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(256, 32, ), verbose=True)\n",
    "mlp.fit(X_train, y_train)\n",
    "report(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: \n",
      "0.814586394232412\n",
      "Test Score: \n",
      "0.7715796918724438\n",
      "Confusion Matrix: \n",
      "[[   6   23    2    0    0   39  111]\n",
      " [   2 7159  122  169   15  382  791]\n",
      " [   0  116 1964   42    1  210  302]\n",
      " [   0  187   39 4729   16   68   83]\n",
      " [   0   22    5    7  211    7    8]\n",
      " [   1  266  280   62    9 2338 2660]\n",
      " [   2  173  337   62    4  803 8684]]\n",
      "Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.03      0.06       181\n",
      "        1.0       0.90      0.83      0.86      8640\n",
      "        2.0       0.71      0.75      0.73      2635\n",
      "        3.0       0.93      0.92      0.93      5122\n",
      "        4.0       0.82      0.81      0.82       260\n",
      "        5.0       0.61      0.42      0.49      5616\n",
      "        6.0       0.69      0.86      0.76     10065\n",
      "\n",
      "avg / total       0.77      0.77      0.76     32519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
